{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Make sure all code is in the PATH.\n",
    "sys.path.append(os.path.normpath(os.path.join('../src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import logging\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "import config, falcon\n",
    "from ms_io import ms_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot styling.\n",
    "plt.style.use(['seaborn-white', 'seaborn-paper'])\n",
    "plt.rc('font', family='serif')\n",
    "sns.set_palette(['#6da7de', '#9e0059', '#dee000', '#d82222', '#5ea15d',\n",
    "                 '#943fa6', '#63c5b5', '#ff38ba', '#eb861e', '#ee266d'])\n",
    "sns.set_context('paper', font_scale=1.3)    # Single-column figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget --timestamping \\\n",
    "    --retry-connrefused \\\n",
    "    --directory-prefix=../data/external \\\n",
    "    --passive-ftp \\\n",
    "    ftp://ftp.pride.ebi.ac.uk/pride/data/archive/2014/04/PXD000561/*.raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p ../data/interim\n",
    "\n",
    "for raw_file in ../data/external/*.raw; do\n",
    "    if [ ! -f ../data/interim/$(basename $raw_file .raw).mgf ]; then\n",
    "        ThermoRawFileParser -i $raw_file -o ../data/interim -f 0\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify MGF spectrum titles for compatibility with msCRUSH.\n",
    "mgf_dir = '../data/interim/'\n",
    "for filename in os.listdir(mgf_dir):\n",
    "    if filename.endswith('.mgf'):\n",
    "        filename = os.path.join(mgf_dir, filename)\n",
    "        spectra = list(ms_io.get_spectra(filename))\n",
    "        ms_io.write_spectra(filename, spectra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = '../data/processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_sizes = [(None, None)]    #, (5, None), (10, None), (50, None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _count_majority_label_mismatch(labels):\n",
    "    labels_assigned = labels.dropna()\n",
    "    if len(labels_assigned) <= 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(labels_assigned) - labels_assigned.value_counts().iat[0]\n",
    "\n",
    "\n",
    "def evaluate_clusters(clusters, min_cluster_size=None, max_cluster_size=None):\n",
    "    clusters = clusters.copy()\n",
    "    # Only consider clusters with specific minimum (inclusive) and/or\n",
    "    # maximum (exclusive) size.\n",
    "    cluster_counts = clusters['cluster'].value_counts(dropna=False)\n",
    "    if min_cluster_size is not None:\n",
    "        clusters.loc[clusters['cluster'].isin(cluster_counts[\n",
    "            cluster_counts < min_cluster_size].index), 'cluster'] = -1\n",
    "    if max_cluster_size is not None:\n",
    "        clusters.loc[clusters['cluster'].isin(cluster_counts[\n",
    "            cluster_counts >= max_cluster_size].index), 'cluster'] = -1\n",
    "\n",
    "    # Use consecutive cluster labels, skipping the noise points.    \n",
    "    cluster_map = clusters['cluster'].value_counts(dropna=False)\n",
    "    if -1 in cluster_map.index:\n",
    "        cluster_map = cluster_map.drop(index=-1)\n",
    "    cluster_map = (cluster_map.to_frame().reset_index().reset_index()\n",
    "                   .rename(columns={'index': 'old', 'level_0': 'new'})\n",
    "                   .set_index('old')['new'])\n",
    "    cluster_map = cluster_map.to_dict(collections.defaultdict(lambda: -1))\n",
    "    clusters['cluster'] = clusters['cluster'].map(cluster_map)\n",
    "    num_clusters = clusters['cluster'].max() + 1\n",
    "\n",
    "    # Reassign noise points to singleton clusters.\n",
    "    noise_mask = clusters['cluster'] == -1\n",
    "    num_noise = noise_mask.sum()\n",
    "    clusters.loc[noise_mask, 'cluster'] = np.arange(\n",
    "        num_clusters, num_clusters + num_noise)\n",
    "\n",
    "    # Compute cluster evaluation measures.\n",
    "    prop_clustered = (len(clusters) - num_noise) / len(clusters)\n",
    "\n",
    "    clusters_ident = clusters.dropna(subset=['sequence'])\n",
    "    clusters_ident_non_noise = (clusters[~noise_mask]\n",
    "                                .dropna(subset=['sequence']))\n",
    "\n",
    "    # The number of incorrectly clustered spectra is the number of PSMs that\n",
    "    # differ from the majority PSM. Unidentified spectra are not considered.\n",
    "    prop_clustered_incorrect = sum(joblib.Parallel(n_jobs=-1)(\n",
    "        joblib.delayed(_count_majority_label_mismatch)(clust['sequence'])\n",
    "        for _, clust in clusters[~noise_mask].groupby('cluster')))\n",
    "    prop_clustered_incorrect /= len(clusters_ident_non_noise)\n",
    "    \n",
    "    # Intuitively similar to accuracy, corrected for random clustering.\n",
    "    # This is only evaluated on non-noise points, because the noise cluster\n",
    "    # randomly groups different, unclustered, peptides.\n",
    "    adjusted_rand_score = metrics.adjusted_rand_score(\n",
    "        clusters_ident_non_noise['sequence'],\n",
    "        clusters_ident_non_noise['cluster'])\n",
    "    \n",
    "    # Mutual information captures the mutual dependence between the ground\n",
    "    # truth and the clustering result (linked to entropy), corrected for\n",
    "    # random clustering.\n",
    "    # This is evaluated on all PSMs, including those clustered as noise.\n",
    "    adjusted_mutual_info_score = metrics.adjusted_mutual_info_score(\n",
    "        clusters_ident['sequence'], clusters_ident['cluster'])\n",
    "\n",
    "    # Homogeneity measures whether clusters contain only identical PSMs.\n",
    "    # This is only evaluated on non-noise points, because the noise cluster\n",
    "    # is highly non-homogeneous by definition.\n",
    "    homogeneity = metrics.homogeneity_score(\n",
    "        clusters_ident_non_noise['sequence'],\n",
    "        clusters_ident_non_noise['cluster'])\n",
    "    # Completeness measures whether identical PSMs are assigned to the same\n",
    "    # cluster.\n",
    "    # This is evaluated on all PSMs, including those clustered as noise.\n",
    "    completeness = metrics.completeness_score(\n",
    "        clusters_ident['sequence'], clusters_ident['cluster'])\n",
    "\n",
    "    return (len(clusters) - num_noise, num_noise,\n",
    "            prop_clustered, prop_clustered_incorrect,\n",
    "            adjusted_rand_score, adjusted_mutual_info_score,\n",
    "            homogeneity, completeness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters_falcon(filename, ids=None):\n",
    "    cluster_labels = pd.read_csv(filename)\n",
    "    if ids is None:\n",
    "        return cluster_labels\n",
    "    else:\n",
    "        cluster_labels = pd.merge(cluster_labels,\n",
    "                                  ids[['identifier', 'sequence']],\n",
    "                                  'left', 'identifier')\n",
    "        cluster_labels['sequence'] = (\n",
    "            cluster_labels['sequence'] + '/' +\n",
    "            cluster_labels['precursor_charge'].astype(str))\n",
    "        return cluster_labels\n",
    "    \n",
    "\n",
    "def get_clusters_maracluster(filename, ids=None):\n",
    "    cluster_labels = (pd.read_csv(filename, sep='\\t',\n",
    "                                  names=['filename', 'scan', 'cluster'])\n",
    "                      .dropna(how='all'))\n",
    "    cluster_labels['identifier'] = (\n",
    "        'mzspec:PXD000561:'\n",
    "        + cluster_labels['filename'].apply(\n",
    "            lambda fn: os.path.splitext(os.path.basename(fn))[0])\n",
    "        + ':scan:' + cluster_labels['scan'].astype(str))\n",
    "    cluster_labels = cluster_labels[['identifier', 'cluster']]\n",
    "    if ids is None:\n",
    "        return cluster_labels\n",
    "    else:\n",
    "        cluster_labels = (pd.merge(cluster_labels,\n",
    "                                   ids[['identifier', 'precursor_charge',\n",
    "                                        'precursor_mz', 'sequence']],\n",
    "                                   'left', 'identifier')\n",
    "                           .dropna(subset=['precursor_charge']))\n",
    "        cluster_labels['sequence'] = (\n",
    "            cluster_labels['sequence'] + '/' +\n",
    "            cluster_labels['precursor_charge'].astype(str))\n",
    "        return cluster_labels\n",
    "    \n",
    "    \n",
    "def get_clusters_mscluster(dir_name, ids=None):\n",
    "    clusters, cluster_i = [], -1\n",
    "    for filename in os.listdir(dir_name):\n",
    "        if filename.endswith('.clust'):\n",
    "            with open(os.path.join(dir_name, filename)) as f_in:\n",
    "                for line in f_in:\n",
    "                    if line.startswith('mscluster'):\n",
    "                        cluster_i += 1\n",
    "                    elif not line.isspace():\n",
    "                        splits = line.split('\\t')\n",
    "                        file_i = int(splits[1])\n",
    "                        spectrum_i = int(splits[2])\n",
    "                        clusters.append((file_i, spectrum_i, cluster_i))\n",
    "    cluster_labels = pd.DataFrame(clusters, columns=['file_i', 'spectrum_i',\n",
    "                                                     'cluster'])\n",
    "    if ids is None:\n",
    "        return cluster_labels\n",
    "    else:\n",
    "        cluster_labels = (pd.merge(cluster_labels, ids,\n",
    "                                   'left', ['file_i', 'spectrum_i'])\n",
    "                          .dropna(subset=['precursor_charge'])\n",
    "                          [['identifier', 'cluster', 'precursor_charge',\n",
    "                            'precursor_mz', 'sequence']])\n",
    "        cluster_labels['precursor_charge'] = \\\n",
    "            cluster_labels['precursor_charge'].astype(int)\n",
    "        cluster_labels['sequence'] = (\n",
    "            cluster_labels['sequence'] + '/' +\n",
    "            cluster_labels['precursor_charge'].astype(str))\n",
    "        return cluster_labels\n",
    "\n",
    "\n",
    "def get_clusters_mscrush(filename, ids=None):\n",
    "    cluster_labels = []\n",
    "    for charge in config.charges:\n",
    "        clusters_charge = pd.read_csv(filename.format(charge), sep='\\t')\n",
    "        clusters_charge['Titles'] = clusters_charge['Titles'].str.split('|')\n",
    "        clusters_charge = clusters_charge.explode('Titles')\n",
    "        clusters_charge['identifier'] = ('mzspec:PXD000561:'\n",
    "                                         + clusters_charge['Titles'])\n",
    "        clusters_charge = clusters_charge.rename(columns={'ID': 'cluster'})\n",
    "        clusters_charge = clusters_charge[['identifier', 'cluster']]\n",
    "        if len(cluster_labels) > 0:\n",
    "            clusters_charge['cluster'] += cluster_labels[-1].iat[-1, 1] + 1\n",
    "        cluster_labels.append(clusters_charge)\n",
    "    cluster_labels = pd.concat(cluster_labels, ignore_index=True)\n",
    "    if ids is None:\n",
    "        return cluster_labels\n",
    "    else:\n",
    "        cluster_labels = (pd.merge(cluster_labels,\n",
    "                                   ids[['identifier', 'precursor_charge',\n",
    "                                        'precursor_mz', 'sequence']],\n",
    "                                   'left', 'identifier')\n",
    "                           .dropna(subset=['precursor_charge']))\n",
    "        cluster_labels['sequence'] = (\n",
    "            cluster_labels['sequence'] + '/' +\n",
    "            cluster_labels['precursor_charge'].astype(str))\n",
    "        return cluster_labels\n",
    "\n",
    "\n",
    "def get_clusters_spectracluster(filename, ids=None):\n",
    "    identifiers, clusters, cluster_i = [], [], -1\n",
    "    with open(filename) as f_in:\n",
    "        for line in f_in:\n",
    "            if line.startswith('=Cluster='):\n",
    "                cluster_i += 1\n",
    "            elif line.startswith('SPEC'):\n",
    "                fn_start_i = line.find('interim/') + len('interim/')\n",
    "                fn_stop_i = line.find('.mgf', fn_start_i)\n",
    "                scan_start_i = line.find('scan=') + len('scan=')\n",
    "                scan_stop_i = line.find('\\t', scan_start_i)\n",
    "                identifiers.append(f'mzspec:PXD000561:'\n",
    "                                   f'{line[fn_start_i:fn_stop_i]}:scan:'\n",
    "                                   f'{line[scan_start_i:scan_stop_i]}')\n",
    "                clusters.append(cluster_i)\n",
    "    cluster_labels = pd.DataFrame({'identifier': identifiers,\n",
    "                                   'cluster': clusters})\n",
    "    if ids is None:\n",
    "        return cluster_labels\n",
    "    else:\n",
    "        cluster_labels = (pd.merge(cluster_labels,\n",
    "                                   ids[['identifier', 'precursor_charge',\n",
    "                                        'precursor_mz', 'sequence']],\n",
    "                                   'left', 'identifier')\n",
    "                          .dropna(subset=['precursor_charge']))\n",
    "        cluster_labels['precursor_charge'] = \\\n",
    "            cluster_labels['precursor_charge'].astype(int)\n",
    "        cluster_labels['sequence'] = (\n",
    "            cluster_labels['sequence'] + '/' +\n",
    "            cluster_labels['precursor_charge'].astype(str))\n",
    "        return cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = pd.read_parquet('kim2014_ids.parquet')\n",
    "ids['sequence'] = ids['sequence'].str.replace('L', 'I')\n",
    "ids = ids[ids['precursor_charge'].isin(config.charges)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### falcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_falcon = os.path.join(work_dir, 'falcon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p ../data/processed/falcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_falcon = {0: 0.05, 1: 0.1, 2: 0.15, 3: 0.2, 4: 0.25, 5: 0.3, 6: 0.35}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.work_dir = dir_falcon\n",
    "for i, eps in hp_falcon.items():\n",
    "    logging.info('hp_falcon run %d (eps=%.2f)', i + 1, eps)\n",
    "    filename = os.path.join(dir_falcon, f'PXD000561_falcon_{i}.csv')\n",
    "    config.eps = eps\n",
    "    # Execute clustering.\n",
    "    if not os.path.isfile(filename):\n",
    "        falcon.main()\n",
    "        os.rename(os.path.join(dir_falcon, 'clusters.csv'), filename)\n",
    "    # Evaluate clustering performance.\n",
    "    cluster_labels = get_clusters_falcon(filename, ids)\n",
    "    for min_cluster_size, max_cluster_size in min_cluster_sizes:\n",
    "        num_clustered, num_noise, \\\n",
    "            prop_clustered, prop_clustered_incorrect, \\\n",
    "            homogeneity, completeness = \\\n",
    "                evaluate_clusters(cluster_labels, min_cluster_size,\n",
    "                                  max_cluster_size)\n",
    "        performance.append(('falcon', eps,\n",
    "                            min_cluster_size, max_cluster_size,\n",
    "                            num_clustered, num_noise,\n",
    "                            prop_clustered, prop_clustered_incorrect,\n",
    "                            homogeneity, completeness))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MaRaCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_maracluster = os.path.join(work_dir, 'maracluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p ../data/processed/maracluster\n",
    "! ls -1 ../data/interim/*.mgf > ../data/processed/maracluster/files.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_maracluster = {0: -3.0, 1: -5.0, 2: -10.0, 3: -15.0, 4: -20.0, 5: -25.0,\n",
    "                  6: -30.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, pval_threshold in hp_maracluster.items():\n",
    "    logging.info('MaRaCluster run %d (p-value threshold=%.1f)',\n",
    "                 i + 1, pval_threshold)\n",
    "    filename_orig = os.path.join(\n",
    "        dir_maracluster,\n",
    "        f'PXD000561_maracluster_{i}.clusters_p{abs(int(pval_threshold))}.tsv')\n",
    "    filename = os.path.join(\n",
    "        dir_maracluster, f'PXD000561_maracluster_{i}.tsv')\n",
    "    # Execute clustering.\n",
    "    cmd = f\"\"\"../bin/maracluster-v1-01-linux-amd64/bin/maracluster batch \\\n",
    "        --batch ../data/processed/maracluster/files.txt \\\n",
    "        --output-folder ../data/processed/maracluster \\\n",
    "        --precursorTolerance 20ppm \\\n",
    "        --pvalThreshold {pval_threshold} \\\n",
    "        --clusterThresholds {pval_threshold} \\\n",
    "        --prefix PXD000561_maracluster_{i}\"\"\"\n",
    "    if not os.path.isfile(filename):\n",
    "        ! eval {cmd} && \\\n",
    "            mv {filename_orig} {filename} && \\\n",
    "            rm {dir_maracluster}/*.dat && \\\n",
    "            rm {dir_maracluster}/*.dat.pvalue_tree.tsv && \\\n",
    "            rm {dir_maracluster}/*.dat_file_list.txt && \\\n",
    "            rm {dir_maracluster}/overlap.pvalue_tree.tsv\n",
    "    # Evaluate clustering performance.\n",
    "    cluster_labels = get_clusters_maracluster(filename, ids)\n",
    "    for min_cluster_size, max_cluster_size in min_cluster_sizes:\n",
    "        num_clustered, num_noise, \\\n",
    "            prop_clustered, prop_clustered_incorrect, \\\n",
    "            homogeneity, completeness = \\\n",
    "                evaluate_clusters(cluster_labels, min_cluster_size,\n",
    "                                  max_cluster_size)\n",
    "        performance.append(('MaRaCluster', (pval_threshold,),\n",
    "                            min_cluster_size, max_cluster_size,\n",
    "                            num_clustered, num_noise,\n",
    "                            prop_clustered, prop_clustered_incorrect,\n",
    "                            homogeneity, completeness))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MS-Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_mscluster = os.path.join(work_dir, 'mscluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p ../data/processed/mscluster\n",
    "realpath ../data/interim/*.mgf > ../data/processed/mscluster/mscluster_spec_list.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_mscluster = {0: 0.0001, 1: 0.001, 2: 0.005, 3: 0.01, 4: 0.05, 5: 0.1,\n",
    "                6: 0.2}\n",
    "rounds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, mixture_prob in hp_mscluster.items():\n",
    "    logging.info('MS-Cluster run %d (mixture-prob=%.3f ; num-rounds=%d)',\n",
    "                 i + 1, mixture_prob, rounds)\n",
    "    dir_mscluster_i = os.path.join(dir_mscluster, f'PXD000561_mscluster_{i}')\n",
    "    # Execute clustering.\n",
    "    cmd = f\"\"\"../bin/MsCluster/MsCluster \\\n",
    "        --model LTQ_TRYP \\\n",
    "        --list {dir_mscluster}/mscluster_spec_list.txt \\\n",
    "        --output-name mscluster \\\n",
    "        --output-file-size 100000000 \\\n",
    "        --out-dir {dir_mscluster_i} \\\n",
    "        --model-dir ../bin/MsCluster/Models \\\n",
    "        --memory-gb 112 \\\n",
    "        --fragment-tolerance 0.05 \\\n",
    "        --precursor-ppm 20 \\\n",
    "        --assign-charges \\\n",
    "        --mixture-prob {mixture_prob} \\\n",
    "        --num-rounds {rounds} \\\n",
    "        --keep-dataset-idx\"\"\"\n",
    "    if not os.path.exists(dir_mscluster_i):\n",
    "        ! eval {cmd} && \\\n",
    "            mv {dir_mscluster_i}/clust/*.clust {dir_mscluster_i} && \\\n",
    "            rm {dir_mscluster_i}/*.txt && \\\n",
    "            rm -rf {dir_mscluster_i}/clust/ && \\\n",
    "            rm -rf {dir_mscluster_i}/mgf/\n",
    "    # Evaluate clustering performance.\n",
    "    cluster_labels = get_clusters_mscluster(dir_mscluster_i, ids)\n",
    "    for min_cluster_size, max_cluster_size in min_cluster_sizes:\n",
    "        num_clustered, num_noise, \\\n",
    "            prop_clustered, prop_clustered_incorrect, \\\n",
    "            homogeneity, completeness = \\\n",
    "                evaluate_clusters(cluster_labels, min_cluster_size,\n",
    "                                  max_cluster_size)\n",
    "        performance.append(('MS-Cluster', (mixture_prob, rounds),\n",
    "                            min_cluster_size, max_cluster_size,\n",
    "                            num_clustered, num_noise,\n",
    "                            prop_clustered, prop_clustered_incorrect,\n",
    "                            homogeneity, completeness))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### msCRUSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_mscrush = os.path.join(work_dir, 'mscrush')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p ../data/processed/mscrush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_mscrush = {i: hp for i, hp in enumerate(itertools.product(\n",
    "    [100], [15], [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (it, h, sim) in hp_mscrush.items():\n",
    "    logging.info('msCRUSH run %d (iteration=%d, hash=%d, similarity=%.2f)',\n",
    "                 i + 1, it, h, sim)\n",
    "    dir_mscrush_i = os.path.join(dir_mscrush, f'PXD000561_mscrush_{i}')\n",
    "    # Execute clustering.\n",
    "    cmd = f\"\"\"../bin/mscrush/mscrush_on_general_charge \\\n",
    "        --files ../data/interim/*.mgf \\\n",
    "        --iteration {it} \\\n",
    "        --hash {h} \\\n",
    "        --thread $(nproc --all) \\\n",
    "        --similarity {sim} \\\n",
    "        --clustering_prefix {dir_mscrush_i}/mscrush\"\"\"\n",
    "    if not os.path.exists(dir_mscrush_i):\n",
    "        os.makedirs(dir_mscrush_i)\n",
    "        ! eval {cmd}\n",
    "    # Evaluate clustering performance.\n",
    "    cluster_labels = get_clusters_mscrush(\n",
    "        os.path.join(dir_mscrush_i, 'mscrush-c{}.txt'), ids)\n",
    "    for min_cluster_size, max_cluster_size in min_cluster_sizes:\n",
    "        num_clustered, num_noise, \\\n",
    "            prop_clustered, prop_clustered_incorrect, \\\n",
    "            homogeneity, completeness = \\\n",
    "                evaluate_clusters(cluster_labels, min_cluster_size,\n",
    "                                  max_cluster_size)\n",
    "        performance.append(('msCRUSH', (it, h, sim),\n",
    "                            min_cluster_size, max_cluster_size,\n",
    "                            num_clustered, num_noise,\n",
    "                            prop_clustered, prop_clustered_incorrect,\n",
    "                            homogeneity, completeness))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spectra_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_spectracluster = os.path.join(work_dir, 'spectra-cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p ../data/processed/spectra-cluster/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_spectracluster = {0: 0.99999, 1: 0.9999, 2: 0.999, 3: 0.99, 4: 0.95,\n",
    "                     5: 0.9, 6: 0.8, 7: 0.7}\n",
    "rounds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, threshold_end in hp_spectracluster.items():\n",
    "    logging.info('spectra-cluster run %d (threshold_end=%.4f ; rounds=%d)',\n",
    "                 i + 1, threshold_end, rounds)\n",
    "    filename = os.path.join(dir_spectracluster,\n",
    "                            f'PXD000561_spectra-cluster_{i}.txt')\n",
    "    # Execute clustering.\n",
    "    cmd = f\"\"\"java -jar ../bin/spectra-cluster/spectra-cluster-cli-1.1.2.jar \\\n",
    "        ../data/interim/*.mgf \\\n",
    "        -binary_directory {dir_spectracluster}/tmp \\\n",
    "        -fast_mode \\\n",
    "        -fragment_tolerance 0.05 \\\n",
    "        -keep_binary_files \\\n",
    "        -major_peak_jobs $(nproc --all) \\\n",
    "        -output_path {filename} \\\n",
    "        -precursor_tolerance 20 \\\n",
    "        -precursor_tolerance_unit ppm \\\n",
    "        -reuse_binary_files \\\n",
    "        -rounds {rounds} \\\n",
    "        -threshold_end {threshold_end} \\\n",
    "        -threshold_start 1.0 \\\n",
    "        -x_disable_mgf_comments\"\"\"\n",
    "    if not os.path.isfile(filename):\n",
    "        ! eval {cmd}\n",
    "    # Evaluate clustering performance.\n",
    "    cluster_labels = get_clusters_spectracluster(filename, ids)\n",
    "    for min_cluster_size, max_cluster_size in min_cluster_sizes:\n",
    "        num_clustered, num_noise, \\\n",
    "            prop_clustered, prop_clustered_incorrect, \\\n",
    "            homogeneity, completeness = \\\n",
    "                evaluate_clusters(cluster_labels, min_cluster_size,\n",
    "                                  max_cluster_size)\n",
    "        performance.append(('spectra-cluster', (threshold_end, rounds),\n",
    "                            min_cluster_size, max_cluster_size,\n",
    "                            num_clustered, num_noise,\n",
    "                            prop_clustered, prop_clustered_incorrect,\n",
    "                            homogeneity, completeness))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame(performance, columns=[\n",
    "    'tool', 'hyperparameters',\n",
    "    'min_cluster_size', 'max_cluster_size',\n",
    "    'num_clustered', 'num_noise',\n",
    "    'prop_clustered', 'prop_clustered_incorrect',\n",
    "    'adjusted_rand_score', 'adjusted_mutual_info_score',\n",
    "    'homogeneity', 'completeness'])\n",
    "performance.to_csv('cluster_comparison.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 7\n",
    "height = width / 1.618\n",
    "fig, axes = plt.subplots(1, 2, figsize=(width * 2, height))\n",
    "axes = np.ravel(axes)\n",
    "\n",
    "# Number of clustered spectra and completeness.\n",
    "for tool in ('falcon', 'MaRaCluster', 'MS-Cluster', 'msCRUSH',\n",
    "             'spectra-cluster'):\n",
    "    tool_performance = performance[(performance['tool'] == tool) &\n",
    "                                   (performance['min_cluster_size'] == 2)]\n",
    "    axes[0].plot(tool_performance['prop_clustered_incorrect'],\n",
    "                 tool_performance['prop_clustered'], marker='o', label=tool)\n",
    "    axes[1].plot(tool_performance['prop_clustered_incorrect'],\n",
    "                 tool_performance['completeness'], marker='o', label=tool)\n",
    "\n",
    "axes[0].set_xlim(0, 0.05)\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[1].set_xlim(0, 0.05)\n",
    "axes[1].set_ylim(0.75, 1)\n",
    "\n",
    "axes[0].xaxis.set_major_formatter(mticker.PercentFormatter(1, 0))\n",
    "axes[0].yaxis.set_major_formatter(mticker.PercentFormatter(1, 0))\n",
    "axes[1].xaxis.set_major_formatter(mticker.PercentFormatter(1, 0))\n",
    "\n",
    "axes[0].set_xlabel('Incorrectly clustered spectra')\n",
    "axes[0].set_ylabel('Clustered spectra')\n",
    "axes[1].set_xlabel('Incorrectly clustered spectra')\n",
    "axes[1].set_ylabel('Completeness')\n",
    "\n",
    "axes[0].legend(loc='lower right', frameon=False)\n",
    "axes[1].legend(loc='lower right', frameon=False)\n",
    "\n",
    "for ax in axes:\n",
    "    sns.despine(ax=ax)\n",
    "    \n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig('cluster_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
