{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Make sure all code is in the PATH.\n",
    "sys.path.append(os.path.normpath(os.path.join('../src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import logging\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "from falcon.ms_io import ms_io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget --timestamping \\\n",
    "    --retry-connrefused \\\n",
    "    --directory-prefix=../data/external \\\n",
    "    --passive-ftp \\\n",
    "    ftp://ftp.pride.ebi.ac.uk/pride/data/archive/2014/04/PXD000561/*.raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p ../data/interim\n",
    "\n",
    "for raw_file in ../data/external/*.raw; do\n",
    "    if [ ! -f ../data/interim/$(basename $raw_file .raw).mgf ]; then\n",
    "        ThermoRawFileParser -i $raw_file -o ../data/interim -f 0\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify MGF spectrum titles for compatibility with msCRUSH.\n",
    "mgf_dir = '../data/interim/'\n",
    "for filename in os.listdir(mgf_dir):\n",
    "    if filename.endswith('.mgf'):\n",
    "        filename = os.path.join(mgf_dir, filename)\n",
    "        spectra = list(ms_io.get_spectra(filename))\n",
    "        ms_io.write_spectra(filename, spectra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = '../data/processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_sizes = [(2, None)]\n",
    "charges = 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     8
    ]
   },
   "outputs": [],
   "source": [
    "def _count_majority_label_mismatch(labels):\n",
    "    labels_assigned = labels.dropna()\n",
    "    if len(labels_assigned) <= 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(labels_assigned) - labels_assigned.value_counts().iat[0]\n",
    "\n",
    "\n",
    "def evaluate_clusters(clusters, min_cluster_size=None, max_cluster_size=None,\n",
    "                      charges=None):\n",
    "    clusters = clusters.copy()\n",
    "    if charges is not None:\n",
    "        clusters = clusters[clusters['precursor_charge'].isin(charges)]\n",
    "\n",
    "    # Use consecutive cluster labels, skipping the noise points.    \n",
    "    cluster_map = clusters['cluster'].value_counts(dropna=False)\n",
    "    if -1 in cluster_map.index:\n",
    "        cluster_map = cluster_map.drop(index=-1)\n",
    "    cluster_map = (cluster_map.to_frame().reset_index().reset_index()\n",
    "                   .rename(columns={'index': 'old', 'level_0': 'new'})\n",
    "                   .set_index('old')['new'])\n",
    "    cluster_map = cluster_map.to_dict(collections.defaultdict(lambda: -1))\n",
    "    clusters['cluster'] = clusters['cluster'].map(cluster_map)\n",
    "\n",
    "    # Reassign noise points to singleton clusters.\n",
    "    noise_mask = clusters['cluster'] == -1\n",
    "    num_clusters = clusters['cluster'].max() + 1\n",
    "    clusters.loc[noise_mask, 'cluster'] = np.arange(\n",
    "        num_clusters, num_clusters + noise_mask.sum())\n",
    "    \n",
    "    # Only consider clusters with specific minimum (inclusive) and/or\n",
    "    # maximum (exclusive) size.\n",
    "    cluster_counts = clusters['cluster'].value_counts(dropna=False)\n",
    "    if min_cluster_size is not None:\n",
    "        clusters.loc[clusters['cluster'].isin(cluster_counts[\n",
    "            cluster_counts < min_cluster_size].index), 'cluster'] = -1\n",
    "    if max_cluster_size is not None:\n",
    "        clusters.loc[clusters['cluster'].isin(cluster_counts[\n",
    "            cluster_counts >= max_cluster_size].index), 'cluster'] = -1\n",
    "\n",
    "    # Compute cluster evaluation measures.\n",
    "    noise_mask = clusters['cluster'] == -1\n",
    "    num_noise = noise_mask.sum()\n",
    "    num_clustered = len(clusters) - num_noise\n",
    "    prop_clustered = (len(clusters) - num_noise) / len(clusters)\n",
    "\n",
    "    clusters_ident = clusters.dropna(subset=['sequence'])\n",
    "    clusters_ident_non_noise = (clusters[~noise_mask]\n",
    "                                .dropna(subset=['sequence']))\n",
    "\n",
    "    # The number of incorrectly clustered spectra is the number of PSMs that\n",
    "    # differ from the majority PSM. Unidentified spectra are not considered.\n",
    "    prop_clustered_incorrect = sum(joblib.Parallel(n_jobs=-1)(\n",
    "        joblib.delayed(_count_majority_label_mismatch)(clust['sequence'])\n",
    "        for _, clust in clusters[~noise_mask].groupby('cluster')))\n",
    "    prop_clustered_incorrect /= len(clusters_ident_non_noise)\n",
    "\n",
    "    # Homogeneity measures whether clusters contain only identical PSMs.\n",
    "    # This is only evaluated on non-noise points, because the noise cluster\n",
    "    # is highly non-homogeneous by definition.\n",
    "    homogeneity = metrics.homogeneity_score(\n",
    "        clusters_ident_non_noise['sequence'],\n",
    "        clusters_ident_non_noise['cluster'])\n",
    "    \n",
    "    # Completeness measures whether identical PSMs are assigned to the same\n",
    "    # cluster.\n",
    "    # This is evaluated on all PSMs, including those clustered as noise.\n",
    "    completeness = metrics.completeness_score(\n",
    "        clusters_ident['sequence'], clusters_ident['cluster'])\n",
    "\n",
    "    return (num_clustered, num_noise,\n",
    "            prop_clustered, prop_clustered_incorrect,\n",
    "            homogeneity, completeness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     14,
     40,
     71,
     103
    ]
   },
   "outputs": [],
   "source": [
    "def get_clusters_falcon(filename, ids=None):\n",
    "    cluster_labels = pd.read_csv(filename, comment='#')\n",
    "    if ids is None:\n",
    "        return cluster_labels\n",
    "    else:\n",
    "        cluster_labels = pd.merge(cluster_labels,\n",
    "                                  ids[['identifier', 'sequence']],\n",
    "                                  'left', 'identifier')\n",
    "        cluster_labels['sequence'] = (\n",
    "            cluster_labels['sequence'] + '/' +\n",
    "            cluster_labels['precursor_charge'].astype(str))\n",
    "        return cluster_labels\n",
    "    \n",
    "\n",
    "def get_clusters_maracluster(filename, ids=None):\n",
    "    cluster_labels = (pd.read_csv(filename, sep='\\t',\n",
    "                                  names=['filename', 'scan', 'cluster'])\n",
    "                      .dropna(how='all'))\n",
    "    cluster_labels['identifier'] = (\n",
    "        'mzspec:PXD000561:'\n",
    "        + cluster_labels['filename'].apply(\n",
    "            lambda fn: os.path.splitext(os.path.basename(fn))[0])\n",
    "        + ':scan:' + cluster_labels['scan'].astype(str))\n",
    "    cluster_labels = cluster_labels[['identifier', 'cluster']]\n",
    "    if ids is None:\n",
    "        return cluster_labels\n",
    "    else:\n",
    "        cluster_labels = (pd.merge(cluster_labels,\n",
    "                                   ids[['identifier', 'precursor_charge',\n",
    "                                        'precursor_mz', 'sequence']],\n",
    "                                   'left', 'identifier')\n",
    "                           .dropna(subset=['precursor_charge']))\n",
    "        cluster_labels['precursor_charge'] = \\\n",
    "            cluster_labels['precursor_charge'].astype(int)\n",
    "        cluster_labels['sequence'] = (\n",
    "            cluster_labels['sequence'] + '/' +\n",
    "            cluster_labels['precursor_charge'].astype(str))\n",
    "        return cluster_labels\n",
    "    \n",
    "    \n",
    "def get_clusters_mscluster(dir_name, ids=None):\n",
    "    clusters, cluster_i = [], -1\n",
    "    for filename in os.listdir(dir_name):\n",
    "        if filename.endswith('.clust'):\n",
    "            with open(os.path.join(dir_name, filename)) as f_in:\n",
    "                for line in f_in:\n",
    "                    if line.startswith('mscluster'):\n",
    "                        cluster_i += 1\n",
    "                    elif not line.isspace():\n",
    "                        splits = line.split('\\t')\n",
    "                        file_i = int(splits[1])\n",
    "                        spectrum_i = int(splits[2])\n",
    "                        clusters.append((file_i, spectrum_i, cluster_i))\n",
    "    cluster_labels = pd.DataFrame(clusters, columns=['file_i', 'spectrum_i',\n",
    "                                                     'cluster'])\n",
    "    if ids is None:\n",
    "        return cluster_labels\n",
    "    else:\n",
    "        cluster_labels = (pd.merge(cluster_labels, ids,\n",
    "                                   'left', ['file_i', 'spectrum_i'])\n",
    "                          .dropna(subset=['precursor_charge'])\n",
    "                          [['identifier', 'cluster', 'precursor_charge',\n",
    "                            'precursor_mz', 'sequence']])\n",
    "        cluster_labels['precursor_charge'] = \\\n",
    "            cluster_labels['precursor_charge'].astype(int)\n",
    "        cluster_labels['sequence'] = (\n",
    "            cluster_labels['sequence'] + '/' +\n",
    "            cluster_labels['precursor_charge'].astype(str))\n",
    "        return cluster_labels\n",
    "\n",
    "\n",
    "def get_clusters_mscrush(dir_name, ids=None):\n",
    "    cluster_labels = []\n",
    "    for filename in os.listdir(dir_name):\n",
    "        if filename.endswith('.txt'):\n",
    "            clusters_file = pd.read_csv(os.path.join(dir_name, filename),\n",
    "                                        sep='\\t')\n",
    "            clusters_file['Titles'] = clusters_file['Titles'].str.split('|')\n",
    "            clusters_file = clusters_file.explode('Titles')\n",
    "            clusters_file['identifier'] = ('mzspec:PXD000561:'\n",
    "                                           + clusters_file['Titles'])\n",
    "            clusters_file = clusters_file.rename(columns={'ID': 'cluster'})\n",
    "            clusters_file = clusters_file[['identifier', 'cluster']]\n",
    "            if len(cluster_labels) > 0:\n",
    "                clusters_file['cluster'] += cluster_labels[-1].iat[-1, 1] + 1\n",
    "            cluster_labels.append(clusters_file)\n",
    "    cluster_labels = pd.concat(cluster_labels, ignore_index=True)\n",
    "    if ids is None:\n",
    "        return cluster_labels\n",
    "    else:\n",
    "        cluster_labels = (pd.merge(cluster_labels,\n",
    "                                   ids[['identifier', 'precursor_charge',\n",
    "                                        'precursor_mz', 'sequence']],\n",
    "                                   'left', 'identifier')\n",
    "                           .dropna(subset=['precursor_charge']))\n",
    "        cluster_labels['precursor_charge'] = \\\n",
    "            cluster_labels['precursor_charge'].astype(int)\n",
    "        cluster_labels['sequence'] = (\n",
    "            cluster_labels['sequence'] + '/' +\n",
    "            cluster_labels['precursor_charge'].astype(str))\n",
    "        return cluster_labels\n",
    "\n",
    "\n",
    "def get_clusters_spectracluster(filename, ids=None):\n",
    "    identifiers, clusters, cluster_i = [], [], -1\n",
    "    with open(filename) as f_in:\n",
    "        for line in f_in:\n",
    "            if line.startswith('=Cluster='):\n",
    "                cluster_i += 1\n",
    "            elif line.startswith('SPEC'):\n",
    "                fn_start_i = line.find('interim/') + len('interim/')\n",
    "                fn_stop_i = line.find('.mgf', fn_start_i)\n",
    "                scan_start_i = line.find('scan=') + len('scan=')\n",
    "                scan_stop_i = line.find('\\t', scan_start_i)\n",
    "                identifiers.append(f'mzspec:PXD000561:'\n",
    "                                   f'{line[fn_start_i:fn_stop_i]}:scan:'\n",
    "                                   f'{line[scan_start_i:scan_stop_i]}')\n",
    "                clusters.append(cluster_i)\n",
    "    cluster_labels = pd.DataFrame({'identifier': identifiers,\n",
    "                                   'cluster': clusters})\n",
    "    if ids is None:\n",
    "        return cluster_labels\n",
    "    else:\n",
    "        cluster_labels = (pd.merge(cluster_labels,\n",
    "                                   ids[['identifier', 'precursor_charge',\n",
    "                                        'precursor_mz', 'sequence']],\n",
    "                                   'left', 'identifier')\n",
    "                          .dropna(subset=['precursor_charge']))\n",
    "        cluster_labels['precursor_charge'] = \\\n",
    "            cluster_labels['precursor_charge'].astype(int)\n",
    "        cluster_labels['sequence'] = (\n",
    "            cluster_labels['sequence'] + '/' +\n",
    "            cluster_labels['precursor_charge'].astype(str))\n",
    "        return cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = pd.read_parquet('kim2014_ids.parquet')\n",
    "ids['sequence'] = ids['sequence'].str.replace('L', 'I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### falcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_falcon = os.path.join(work_dir, 'falcon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p ../data/processed/falcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_falcon = {0: 0.05, 1: 0.10, 2: 0.15, 3: 0.20, 4: 0.25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, eps in hp_falcon.items():\n",
    "    logging.info('falcon run %d (eps=%.2f)', i + 1, eps)\n",
    "    filename = os.path.join(dir_falcon, f'PXD000561_falcon_{i}.csv')\n",
    "    # Execute clustering.\n",
    "    cmd = f\"\"\"falcon \\\n",
    "        ../data/interim/*.mgf \\\n",
    "        ../data/processed/falcon/PXD000561_falcon_{i} \\\n",
    "        --usi_pxd PXD000561 \\\n",
    "        --eps {eps}\"\"\"\n",
    "    if not os.path.isfile(filename):\n",
    "        ! eval {cmd}\n",
    "    # Evaluate clustering performance.\n",
    "    cluster_labels = get_clusters_falcon(filename, ids)\n",
    "    for min_cluster_size, max_cluster_size in min_cluster_sizes:\n",
    "        num_clustered, num_noise, \\\n",
    "            prop_clustered, prop_clustered_incorrect, \\\n",
    "            homogeneity, completeness = \\\n",
    "                evaluate_clusters(cluster_labels, min_cluster_size,\n",
    "                                  max_cluster_size, charges)\n",
    "        performance.append(('falcon', (eps,),\n",
    "                            min_cluster_size, max_cluster_size,\n",
    "                            num_clustered, num_noise,\n",
    "                            prop_clustered, prop_clustered_incorrect,\n",
    "                            homogeneity, completeness))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MaRaCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_maracluster = os.path.join(work_dir, 'maracluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p ../data/processed/maracluster\n",
    "! ls -1 ../data/interim/*.mgf > ../data/processed/maracluster/files.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_maracluster = {0: -2.0, 1: -3.0, 2: -5.0, 3: -10.0, 4: -15.0, 5: -20.0,\n",
    "                  6: -25.0, 7: -30.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, pval_threshold in hp_maracluster.items():\n",
    "    logging.info('MaRaCluster run %d (p-value threshold=%.1f)',\n",
    "                 i + 1, pval_threshold)\n",
    "    filename_orig = os.path.join(\n",
    "        dir_maracluster,\n",
    "        f'PXD000561_maracluster_{i}.clusters_p{abs(int(pval_threshold))}.tsv')\n",
    "    filename = os.path.join(\n",
    "        dir_maracluster, f'PXD000561_maracluster_{i}.tsv')\n",
    "    # Execute clustering.\n",
    "    cmd = f\"\"\"../bin/maracluster-v1-01-linux-amd64/bin/maracluster batch \\\n",
    "        --batch ../data/processed/maracluster/files.txt \\\n",
    "        --output-folder ../data/processed/maracluster \\\n",
    "        --precursorTolerance 20ppm \\\n",
    "        --pvalThreshold {pval_threshold} \\\n",
    "        --clusterThresholds {pval_threshold} \\\n",
    "        --prefix PXD000561_maracluster_{i}\"\"\"\n",
    "    if not os.path.isfile(filename):\n",
    "        ! eval {cmd} && \\\n",
    "            mv {filename_orig} {filename} && \\\n",
    "            rm {dir_maracluster}/*.dat && \\\n",
    "            rm {dir_maracluster}/*.dat.pvalue_tree.tsv && \\\n",
    "            rm {dir_maracluster}/*.dat_file_list.txt && \\\n",
    "            rm {dir_maracluster}/overlap.pvalue_tree.tsv\n",
    "    # Evaluate clustering performance.\n",
    "    cluster_labels = get_clusters_maracluster(filename, ids)\n",
    "    for min_cluster_size, max_cluster_size in min_cluster_sizes:\n",
    "        num_clustered, num_noise, \\\n",
    "            prop_clustered, prop_clustered_incorrect, \\\n",
    "            homogeneity, completeness = \\\n",
    "                evaluate_clusters(cluster_labels, min_cluster_size,\n",
    "                                  max_cluster_size, charges)\n",
    "        performance.append(('MaRaCluster', (pval_threshold,),\n",
    "                            min_cluster_size, max_cluster_size,\n",
    "                            num_clustered, num_noise,\n",
    "                            prop_clustered, prop_clustered_incorrect,\n",
    "                            homogeneity, completeness))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MS-Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_mscluster = os.path.join(work_dir, 'mscluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p ../data/processed/mscluster\n",
    "realpath ../data/interim/*.mgf > ../data/processed/mscluster/mscluster_spec_list.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_mscluster = {0: 0.0001, 1: 0.001, 2: 0.005, 3: 0.01, 4: 0.05, 5: 0.1}\n",
    "rounds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, mixture_prob in hp_mscluster.items():\n",
    "    logging.info('MS-Cluster run %d (mixture-prob=%.3f ; num-rounds=%d)',\n",
    "                 i + 1, mixture_prob, rounds)\n",
    "    dir_mscluster_i = os.path.join(dir_mscluster, f'PXD000561_mscluster_{i}')\n",
    "    # Execute clustering.\n",
    "    cmd = f\"\"\"../bin/MsCluster/MsCluster \\\n",
    "        --model LTQ_TRYP \\\n",
    "        --list {dir_mscluster}/mscluster_spec_list.txt \\\n",
    "        --output-name mscluster \\\n",
    "        --output-file-size 100000000 \\\n",
    "        --out-dir {dir_mscluster_i} \\\n",
    "        --model-dir ../bin/MsCluster/Models \\\n",
    "        --memory-gb 112 \\\n",
    "        --fragment-tolerance 0.05 \\\n",
    "        --precursor-ppm 20 \\\n",
    "        --assign-charges \\\n",
    "        --mixture-prob {mixture_prob} \\\n",
    "        --num-rounds {rounds} \\\n",
    "        --keep-dataset-idx\"\"\"\n",
    "    if not os.path.exists(dir_mscluster_i):\n",
    "        ! eval {cmd} && \\\n",
    "            mv {dir_mscluster_i}/clust/*.clust {dir_mscluster_i} && \\\n",
    "            rm {dir_mscluster_i}/*.txt && \\\n",
    "            rm -rf {dir_mscluster_i}/clust/ && \\\n",
    "            rm -rf {dir_mscluster_i}/mgf/\n",
    "    # Evaluate clustering performance.\n",
    "    cluster_labels = get_clusters_mscluster(dir_mscluster_i, ids)\n",
    "    for min_cluster_size, max_cluster_size in min_cluster_sizes:\n",
    "        num_clustered, num_noise, \\\n",
    "            prop_clustered, prop_clustered_incorrect, \\\n",
    "            homogeneity, completeness = \\\n",
    "                evaluate_clusters(cluster_labels, min_cluster_size,\n",
    "                                  max_cluster_size, charges)\n",
    "        performance.append(('MS-Cluster', (mixture_prob, rounds),\n",
    "                            min_cluster_size, max_cluster_size,\n",
    "                            num_clustered, num_noise,\n",
    "                            prop_clustered, prop_clustered_incorrect,\n",
    "                            homogeneity, completeness))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### msCRUSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_mscrush = os.path.join(work_dir, 'mscrush')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p ../data/processed/mscrush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_mscrush = {0: (100, 15, 0.3), 1: (100, 15, 0.4), 2: (100, 15, 0.5),\n",
    "              3: (100, 15, 0.6), 4: (100, 15, 0.7), 5: (100, 15, 0.8)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (it, h, sim) in hp_mscrush.items():\n",
    "    logging.info('msCRUSH run %d (iteration=%d, hash=%d, similarity=%.2f)',\n",
    "                 i + 1, it, h, sim)\n",
    "    dir_mscrush_i = os.path.join(dir_mscrush, f'PXD000561_mscrush_{i}')\n",
    "    # Execute clustering.\n",
    "    cmd = f\"\"\"../bin/mscrush/mscrush_on_general_charge \\\n",
    "        --files ../data/interim/*.mgf \\\n",
    "        --iteration {it} \\\n",
    "        --hash {h} \\\n",
    "        --thread $(nproc --all) \\\n",
    "        --similarity {sim} \\\n",
    "        --clustering_prefix {dir_mscrush_i}/mscrush\"\"\"\n",
    "    if not os.path.exists(dir_mscrush_i):\n",
    "        os.makedirs(dir_mscrush_i)\n",
    "        ! eval {cmd}\n",
    "    # Evaluate clustering performance.\n",
    "    cluster_labels = get_clusters_mscrush(dir_mscrush_i, ids)\n",
    "    for min_cluster_size, max_cluster_size in min_cluster_sizes:\n",
    "        num_clustered, num_noise, \\\n",
    "            prop_clustered, prop_clustered_incorrect, \\\n",
    "            homogeneity, completeness = \\\n",
    "                evaluate_clusters(cluster_labels, min_cluster_size,\n",
    "                                  max_cluster_size, charges)\n",
    "        performance.append(('msCRUSH', (it, h, sim),\n",
    "                            min_cluster_size, max_cluster_size,\n",
    "                            num_clustered, num_noise,\n",
    "                            prop_clustered, prop_clustered_incorrect,\n",
    "                            homogeneity, completeness))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spectra_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_spectracluster = os.path.join(work_dir, 'spectra-cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p ../data/processed/spectra-cluster/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_spectracluster = {0: 0.99999, 1: 0.9999, 2: 0.999, 3: 0.99, 4: 0.95,\n",
    "                     5: 0.9, 6: 0.8}\n",
    "rounds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, threshold_end in hp_spectracluster.items():\n",
    "    logging.info('spectra-cluster run %d (threshold_end=%.4f ; rounds=%d)',\n",
    "                 i + 1, threshold_end, rounds)\n",
    "    filename = os.path.join(dir_spectracluster,\n",
    "                            f'PXD000561_spectra-cluster_{i}.txt')\n",
    "    # Execute clustering.\n",
    "    cmd = f\"\"\"java -jar ../bin/spectra-cluster/spectra-cluster-cli-1.1.2.jar \\\n",
    "        ../data/interim/*.mgf \\\n",
    "        -binary_directory {dir_spectracluster}/tmp \\\n",
    "        -fast_mode \\\n",
    "        -fragment_tolerance 0.05 \\\n",
    "        -keep_binary_files \\\n",
    "        -major_peak_jobs $(nproc --all) \\\n",
    "        -output_path {filename} \\\n",
    "        -precursor_tolerance 20 \\\n",
    "        -precursor_tolerance_unit ppm \\\n",
    "        -reuse_binary_files \\\n",
    "        -rounds {rounds} \\\n",
    "        -threshold_end {threshold_end} \\\n",
    "        -threshold_start 1.0 \\\n",
    "        -x_disable_mgf_comments\"\"\"\n",
    "    if not os.path.isfile(filename):\n",
    "        ! eval {cmd}\n",
    "    # Evaluate clustering performance.\n",
    "    cluster_labels = get_clusters_spectracluster(filename, ids)\n",
    "    for min_cluster_size, max_cluster_size in min_cluster_sizes:\n",
    "        num_clustered, num_noise, \\\n",
    "            prop_clustered, prop_clustered_incorrect, \\\n",
    "            homogeneity, completeness = \\\n",
    "                evaluate_clusters(cluster_labels, min_cluster_size,\n",
    "                                  max_cluster_size, charges)\n",
    "        performance.append(('spectra-cluster', (threshold_end, rounds),\n",
    "                            min_cluster_size, max_cluster_size,\n",
    "                            num_clustered, num_noise,\n",
    "                            prop_clustered, prop_clustered_incorrect,\n",
    "                            homogeneity, completeness))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export clustering hyperparameter results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame(performance, columns=[\n",
    "    'tool', 'hyperparameters',\n",
    "    'min_cluster_size', 'max_cluster_size',\n",
    "    'num_clustered', 'num_noise',\n",
    "    'prop_clustered', 'prop_clustered_incorrect',\n",
    "    'homogeneity', 'completeness'])\n",
    "performance.to_csv('cluster_comparison_hyperparam.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
